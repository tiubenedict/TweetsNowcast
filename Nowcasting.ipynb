{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nowcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install numpy pandas matplotlib statsmodels scipy scikit-learn openpyxl\n",
    "# !pip3 freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "# from ExtendedDynamicFactor import ExtendedDynamicFactor, OptimizeExtendedDynamicFactor\n",
    "import dynamicfactoranalysis.dynamicfactoranalysis as dfa\n",
    "from NowcastingPipeline import NowcastingPH\n",
    "\n",
    "import multiprocessing as mp\n",
    "mp_fork = mp.get_context('fork')\n",
    "processes = int(mp.cpu_count() * 2/3)\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Factor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NowcastingDFM(NowcastingPH):\n",
    "    def set_classname(self, **kwargs):\n",
    "        self.prefix = ('DFM_Opt' if self.kwargs.get(\"optimize_order\") else f'DFM{self.kwargs.get(\"DFM_order\")}')   # Override class name\n",
    "    def fit_model(self, vintage, window, DFM_order, optimize_order, **kwargs):\n",
    "        df, target_scaler, econ_scaler = self.load_data(vintage, window=window, **kwargs)\n",
    "        factor_order, error_order, k_factors, factor_lag = DFM_order\n",
    "        # drop row if not enough non-missing (max safety)\n",
    "        df = df.dropna(thresh = k_factors * (1 + factor_lag))\n",
    "\n",
    "        if optimize_order:\n",
    "            model_ = dfa.DynamicFactorModelOptimizer(\n",
    "                endog=df, k_factors_max=k_factors, factor_lag_max=factor_lag, factor_order_max=factor_order, \n",
    "                error_order_max=error_order, verbose=True, **kwargs).fit(**kwargs)\n",
    "        else:\n",
    "            model_ = dfa.DynamicFactorModel(\n",
    "                endog=df, k_factors=k_factors, factor_lag=factor_lag, factor_order=factor_order, \n",
    "                error_order=error_order, **kwargs)\n",
    "        \n",
    "        model = model_.fit(disp=False, maxiter=1000, method='powell', ftol=1e-5, **kwargs)\n",
    "        # model = model_.fit(disp=False, maxiter=10, method='powell', ftol=1e-3, **kwargs)\n",
    "        DFM_order = (model_.factor_order, model_.error_order, model_.k_factors, model_.factor_lag)\n",
    "        self.prefix = 'DFM_Opt' if optimize_order else f'DFM{DFM_order}'    # Override class name\n",
    "        \n",
    "        nowcasts = model.predict(start=f'{vintage.year}Q1', end=f'{vintage.year}Q4')[['target']]\n",
    "        nowcasts = list(target_scaler.inverse_transform(nowcasts[['target']]).flatten())\n",
    "        model_desc = f'DFM{DFM_order}'\n",
    "\n",
    "        return nowcasts, model_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sample DFM_Opt(2,2,2,0) E\n",
    "target = 'GDP'\n",
    "# target = 'GDPG_Est'\n",
    "kmpair = {}\n",
    "window = 1000\n",
    "model = NowcastingDFM(DFM_order=(2,2,2,0), target=target, optimize_order=True, kmpair=kmpair, enforce_stationarity=True) # DFM_order = factor_order, error_order, k_factors, factor_lag\n",
    "summary = model.run(window=window, save_aggregate=True, with_econ=True, with_tweets=False, multiprocess=1, start=pd.to_datetime('2017-01-31'))\n",
    "# summary = pd.read_csv('Results/DFM_Opt_W1000_GDP_E_summary.csv', parse_dates=['date'])\n",
    "tweets = model.load_tweets('2023-01-01', window=window+72, kmpair=kmpair).loc[dt.datetime(2017,1,1):,:]\n",
    "tweets.index = tweets.index.to_timestamp()\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "axs[0].plot(summary['date'], summary['Nowcast_A'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[0].plot(summary['date'], summary['Actual_A'], label='Actual')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Annual GDP Growth')\n",
    "axs[1].plot(summary['date'], summary['Nowcast_Q'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[1].plot(summary['date'], summary['Actual_Q'], label='Actual')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Quarter GDP Growth')\n",
    "for metric in tweets.columns:\n",
    "    axs[2].plot(tweets.index, tweets[metric], label=metric, alpha=0.5)\n",
    "axs[2].legend()\n",
    "axs[2].set_title('Econ Metrics')\n",
    "fig.show()\n",
    "summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NowcastingML(NowcastingPH):\n",
    "    def set_classname(self, **kwargs):\n",
    "        self.prefix = f'ENet{self.kwargs.get(\"lag_order\")}'    # Override class name\n",
    "    def lag_data(self, df, lag_order):\n",
    "        target_lag, tweet_lag, econ_lag = lag_order\n",
    "        lagged_df = ([df] + [df[['target']].shift(l).add_suffix(f'.Q{l}') for l in range(1, target_lag + 1)] + \n",
    "                        [df[[col for col in df.columns if 'TWT' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, tweet_lag + 1)] +\n",
    "                        [df[[col for col in df.columns if 'ECN' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, econ_lag + 1)])\n",
    "        df = pd.concat(lagged_df, axis=1)\n",
    "        df = df.loc[:, ~df.T.duplicated(keep='first')]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fit_model(self, vintage, window, lag_order, **kwargs):\n",
    "        df, target_scaler, econ_scaler = self.load_data(vintage, window=window, **kwargs)\n",
    "        df = self.lag_data(df, lag_order)\n",
    "\n",
    "        X_test = df.loc[vintage + relativedelta(month=3) :, df.columns.drop('target')]\n",
    "        df_train = df.loc[: vintage - relativedelta(months=3), :].dropna()\n",
    "        X_train = df_train.loc[:, df_train.columns.drop('target')]\n",
    "        y_train = df_train.loc[:, 'target']\n",
    "        \n",
    "        model = ElasticNet()\n",
    "        model.fit(X_train, y_train)\n",
    "        self.prefix = f'ENet{lag_order}'    # Override class name\n",
    "\n",
    "        nowcasts = [(model.predict(X_test_.to_frame().T)[0] if not X_test_.isnull().values.any() else np.nan) for _, X_test_ in X_test.iterrows()]\n",
    "        nowcasts = list(target_scaler.inverse_transform(np.array(nowcasts).reshape(-1,1)).flatten())\n",
    "        model_desc = f'ENet{lag_order}'\n",
    "\n",
    "        return nowcasts, model_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'GDP'\n",
    "kmpair = {}\n",
    "window = 37\n",
    "model = NowcastingML(lag_order=(4,1,0), kmpair=kmpair, target=target) # lag_order = target_lag, tweet_lag, econ_lag\n",
    "summary = model.run(window=window, save_aggregate=True, with_econ=False, with_tweets=True, multiprocess=processes)\n",
    "# summary = pd.read_csv('Results/ENet(2, 1, 0)_W25_TE_summary.csv', parse_dates=['date'])\n",
    "tweets = model.load_tweets('2023-01-01').loc[dt.datetime(2017,1,1):,:]\n",
    "tweets.index = tweets.index.to_timestamp()\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "axs[0].plot(summary['date'], summary['Nowcast_A'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[0].plot(summary['date'], summary['Actual_A'], label='Actual')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Annual GDP Growth')\n",
    "axs[1].plot(summary['date'], summary['Nowcast_Q'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[1].plot(summary['date'], summary['Actual_Q'], label='Actual')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Quarter GDP Growth')\n",
    "for metric in tweets.columns:\n",
    "    axs[2].plot(tweets.index, tweets[metric], label=metric, alpha=0.5)\n",
    "axs[2].legend()\n",
    "axs[2].set_title('Tweet Metrics')\n",
    "fig.show()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NowcastingMLP(NowcastingPH):\n",
    "    def set_classname(self, **kwargs):\n",
    "        self.prefix = f'MLP{self.kwargs.get(\"lag_order\")}'    # Override class name\n",
    "    def lag_data(self, df, lag_order):\n",
    "        target_lag, tweet_lag, econ_lag = lag_order\n",
    "        lagged_df = ([df] + [df[['target']].shift(l).add_suffix(f'.Q{l}') for l in range(1, target_lag + 1)] + \n",
    "                        [df[[col for col in df.columns if 'TWT' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, tweet_lag + 1)] +\n",
    "                        [df[[col for col in df.columns if 'ECN' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, econ_lag + 1)])\n",
    "        df = pd.concat(lagged_df, axis=1)\n",
    "        df = df.loc[:, ~df.T.duplicated(keep='first')]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fit_model(self, vintage, window, lag_order, **kwargs):\n",
    "        df, target_scaler, econ_scaler = self.load_data(vintage, window=window, **kwargs)\n",
    "        df = self.lag_data(df, lag_order)\n",
    "\n",
    "        X_test = df.loc[vintage + relativedelta(month=3) :, df.columns.drop('target')]\n",
    "        df_train = df.loc[: vintage - relativedelta(months=3), :].dropna()\n",
    "        X_train = df_train.loc[:, df_train.columns.drop('target')]\n",
    "        y_train = df_train.loc[:, 'target']\n",
    "        \n",
    "        model = MLPRegressor(random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        self.prefix = f'MLP{lag_order}'    # Override class name\n",
    "\n",
    "        nowcasts = [(model.predict(X_test_.to_frame().T)[0] if not X_test_.isnull().values.any() else np.nan) for _, X_test_ in X_test.iterrows()]\n",
    "        nowcasts = list(target_scaler.inverse_transform(np.array(nowcasts).reshape(-1,1)).flatten())\n",
    "        model_desc = f'MLP{lag_order}'\n",
    "\n",
    "        return nowcasts, model_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'GDP'\n",
    "kmpair = {}\n",
    "window = 37\n",
    "model = NowcastingMLP(lag_order=(4,1,0), kmpair=kmpair, target=target) # lag_order = target_lag, tweet_lag, econ_lag\n",
    "summary = model.run(window=window, save_aggregate=True, with_econ=False, with_tweets=True, multiprocess=processes)\n",
    "# summary = pd.read_csv('Results/ENet(2, 1, 0)_W25_TE_summary.csv', parse_dates=['date'])\n",
    "tweets = model.load_tweets('2023-01-01', kmpair=kmpair, window=window+72).loc[dt.datetime(2017,1,1):,:]\n",
    "tweets.index = tweets.index.to_timestamp()\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "axs[0].plot(summary['date'], summary['Nowcast_A'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[0].plot(summary['date'], summary['Actual_A'], label='Actual')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Annual GDP Growth')\n",
    "axs[1].plot(summary['date'], summary['Nowcast_Q'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[1].plot(summary['date'], summary['Actual_Q'], label='Actual')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Quarter GDP Growth')\n",
    "for metric in tweets.columns:\n",
    "    axs[2].plot(tweets.index, tweets[metric], label=metric, alpha=0.5)\n",
    "axs[2].legend()\n",
    "axs[2].set_title('Tweet Metrics')\n",
    "fig.show()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NowcastingSVR(NowcastingPH):\n",
    "    def set_classname(self, **kwargs):\n",
    "        self.prefix = f'SVR{self.kwargs.get(\"lag_order\")}'    # Override class name\n",
    "    def lag_data(self, df, lag_order):\n",
    "        target_lag, tweet_lag, econ_lag = lag_order\n",
    "        lagged_df = ([df] + [df[['target']].shift(l).add_suffix(f'.Q{l}') for l in range(1, target_lag + 1)] + \n",
    "                        [df[[col for col in df.columns if 'TWT' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, tweet_lag + 1)] +\n",
    "                        [df[[col for col in df.columns if 'ECN' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, econ_lag + 1)])\n",
    "        df = pd.concat(lagged_df, axis=1)\n",
    "        df = df.loc[:, ~df.T.duplicated(keep='first')]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fit_model(self, vintage, window, lag_order, **kwargs):\n",
    "        df, target_scaler, econ_scaler = self.load_data(vintage, window=window, **kwargs)\n",
    "        df = self.lag_data(df, lag_order)\n",
    "\n",
    "        X_test = df.loc[vintage + relativedelta(month=3) :, df.columns.drop('target')]\n",
    "        df_train = df.loc[: vintage - relativedelta(months=3), :].dropna()\n",
    "        X_train = df_train.loc[:, df_train.columns.drop('target')]\n",
    "        y_train = df_train.loc[:, 'target']\n",
    "        \n",
    "        model = SVR()\n",
    "        model.fit(X_train, y_train)\n",
    "        self.prefix = f'SVR{lag_order}'    # Override class name\n",
    "\n",
    "        nowcasts = [(model.predict(X_test_.to_frame().T)[0] if not X_test_.isnull().values.any() else np.nan) for _, X_test_ in X_test.iterrows()]\n",
    "        nowcasts = list(target_scaler.inverse_transform(np.array(nowcasts).reshape(-1,1)).flatten())\n",
    "        model_desc = f'SVR{lag_order}'\n",
    "\n",
    "        return nowcasts, model_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'GDP'\n",
    "kmpair = {}\n",
    "window = 37\n",
    "model = NowcastingSVR(lag_order=(4,1,0), kmpair=kmpair, target=target) # lag_order = target_lag, tweet_lag, econ_lag\n",
    "summary = model.run(window=window, save_aggregate=True, with_econ=False, with_tweets=True, multiprocess=processes)\n",
    "# summary = pd.read_csv('Results/ENet(2, 1, 0)_W25_TE_summary.csv', parse_dates=['date'])\n",
    "tweets = model.load_tweets('2023-01-01', kmpair=kmpair, window=window+72).loc[dt.datetime(2017,1,1):,:]\n",
    "tweets.index = tweets.index.to_timestamp()\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "axs[0].plot(summary['date'], summary['Nowcast_A'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[0].plot(summary['date'], summary['Actual_A'], label='Actual')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Annual GDP Growth')\n",
    "axs[1].plot(summary['date'], summary['Nowcast_Q'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[1].plot(summary['date'], summary['Actual_Q'], label='Actual')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Quarter GDP Growth')\n",
    "for metric in tweets.columns:\n",
    "    axs[2].plot(tweets.index, tweets[metric], label=metric, alpha=0.5)\n",
    "axs[2].legend()\n",
    "axs[2].set_title('Tweet Metrics')\n",
    "fig.show()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NowcastingExtraTree(NowcastingPH):\n",
    "    def set_classname(self, **kwargs):\n",
    "        self.prefix = f'ExtraTrees{self.kwargs.get(\"lag_order\")}'    # Override class name\n",
    "    def lag_data(self, df, lag_order):\n",
    "        target_lag, tweet_lag, econ_lag = lag_order\n",
    "        lagged_df = ([df] + [df[['target']].shift(l).add_suffix(f'.Q{l}') for l in range(1, target_lag + 1)] + \n",
    "                        [df[[col for col in df.columns if 'TWT' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, tweet_lag + 1)] +\n",
    "                        [df[[col for col in df.columns if 'ECN' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, econ_lag + 1)])\n",
    "        df = pd.concat(lagged_df, axis=1)\n",
    "        df = df.loc[:, ~df.T.duplicated(keep='first')]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fit_model(self, vintage, window, lag_order, **kwargs):\n",
    "        df, target_scaler, econ_scaler = self.load_data(vintage, window=window, **kwargs)\n",
    "        df = self.lag_data(df, lag_order)\n",
    "\n",
    "        X_test = df.loc[vintage + relativedelta(month=3) :, df.columns.drop('target')]\n",
    "        df_train = df.loc[: vintage - relativedelta(months=3), :].dropna()\n",
    "        X_train = df_train.loc[:, df_train.columns.drop('target')]\n",
    "        y_train = df_train.loc[:, 'target']\n",
    "        \n",
    "        model = ExtraTreesRegressor(random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        self.prefix = f'ExtraTrees{lag_order}'    # Override class name\n",
    "\n",
    "        nowcasts = [(model.predict(X_test_.to_frame().T)[0] if not X_test_.isnull().values.any() else np.nan) for _, X_test_ in X_test.iterrows()]\n",
    "        nowcasts = list(target_scaler.inverse_transform(np.array(nowcasts).reshape(-1,1)).flatten())\n",
    "        model_desc = f'ExtraTrees{lag_order}'\n",
    "\n",
    "        return nowcasts, model_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'GDP'\n",
    "kmpair = {}\n",
    "window = 37\n",
    "model = NowcastingExtraTree(lag_order=(4,1,0), kmpair=kmpair, target=target) # lag_order = target_lag, tweet_lag, econ_lag\n",
    "summary = model.run(window=window, save_aggregate=True, with_econ=False, with_tweets=True, multiprocess=processes)\n",
    "# summary = pd.read_csv('Results/ENet(2, 1, 0)_W25_TE_summary.csv', parse_dates=['date'])\n",
    "tweets = model.load_tweets('2023-01-01', kmpair=kmpair, window=window+72).loc[dt.datetime(2017,1,1):,:]\n",
    "tweets.index = tweets.index.to_timestamp()\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "axs[0].plot(summary['date'], summary['Nowcast_A'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[0].plot(summary['date'], summary['Actual_A'], label='Actual')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Annual GDP Growth')\n",
    "axs[1].plot(summary['date'], summary['Nowcast_Q'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[1].plot(summary['date'], summary['Actual_Q'], label='Actual')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Quarter GDP Growth')\n",
    "for metric in tweets.columns:\n",
    "    axs[2].plot(tweets.index, tweets[metric], label=metric, alpha=0.5)\n",
    "axs[2].legend()\n",
    "axs[2].set_title('Tweet Metrics')\n",
    "fig.show()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NowcastingXGBoost(NowcastingPH):\n",
    "    def set_classname(self, **kwargs):\n",
    "        self.prefix = f'XGBoost{self.kwargs.get(\"lag_order\")}'    # Override class name\n",
    "    def lag_data(self, df, lag_order):\n",
    "        target_lag, tweet_lag, econ_lag = lag_order\n",
    "        lagged_df = ([df] + [df[['target']].shift(l).add_suffix(f'.Q{l}') for l in range(1, target_lag + 1)] + \n",
    "                        [df[[col for col in df.columns if 'TWT' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, tweet_lag + 1)] +\n",
    "                        [df[[col for col in df.columns if 'ECN' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, econ_lag + 1)])\n",
    "        df = pd.concat(lagged_df, axis=1)\n",
    "        df = df.loc[:, ~df.T.duplicated(keep='first')]\n",
    "\n",
    "        return df\n",
    "    def fit_model(self, vintage, window, lag_order, **kwargs):\n",
    "        df, target_scaler, econ_scaler = self.load_data(vintage, window=window, **kwargs)\n",
    "        df = self.lag_data(df, lag_order)\n",
    "\n",
    "        X_test = df.loc[vintage + relativedelta(month=3) :, df.columns.drop('target')]\n",
    "        df_train = df.loc[: vintage - relativedelta(months=3), :].dropna()\n",
    "        X_train = df_train.loc[:, df_train.columns.drop('target')]\n",
    "        y_train = df_train.loc[:, 'target']\n",
    "        \n",
    "        model = XGBRegressor(objective='reg:squarederror', n_estimators=1000, nthread=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        self.prefix = f'XGBoost{lag_order}'    # Override class name\n",
    "\n",
    "        nowcasts = [(model.predict(X_test_.to_frame().T)[0] if not X_test_.isnull().values.any() else np.nan) for _, X_test_ in X_test.iterrows()]\n",
    "        nowcasts = list(target_scaler.inverse_transform(np.array(nowcasts).reshape(-1,1)).flatten())\n",
    "        model_desc = f'XGBoost{lag_order}'\n",
    "\n",
    "        return nowcasts, model_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='GDP'\n",
    "kmpair = {}\n",
    "window = 25\n",
    "model = NowcastingXGBoost(lag_order=(4,1,0), kmpair=kmpair, target=target) # lag_order = target_lag, tweet_lag, econ_lag\n",
    "summary = model.run(window=window, save_aggregate=True, with_econ=False, with_tweets=True, multiprocess=processes)\n",
    "# summary = pd.read_csv('Results/ENet(2, 1, 0)_W25_TE_summary.csv', parse_dates=['date'])\n",
    "tweets = model.load_tweets('2023-01-01', kmpair=kmpair, window=window).loc[dt.datetime(2017,1,1):,:]\n",
    "tweets.index = tweets.index.to_timestamp()\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "axs[0].plot(summary['date'], summary['Nowcast_A'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[0].plot(summary['date'], summary['Actual_A'], label='Actual')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Annual GDP Growth')\n",
    "axs[1].plot(summary['date'], summary['Nowcast_Q'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[1].plot(summary['date'], summary['Actual_Q'], label='Actual')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Quarter GDP Growth')\n",
    "for metric in tweets.columns:\n",
    "    axs[2].plot(tweets.index, tweets[metric], label=metric, alpha=0.5)\n",
    "axs[2].legend()\n",
    "axs[2].set_title('Tweet Metrics')\n",
    "fig.show()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3PRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "\n",
    "class TPRF():\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "    def autoproxy(self, X, y, n_proxy):\n",
    "        \"\"\"\n",
    "        Use the autoproxy algorithm for calculating the proxies,\n",
    "        given an array of predictors and corresponding target values\n",
    "\n",
    "        :param X: Array of predictors\n",
    "        :param y: Array of returns (target values)\n",
    "        :param n_proxy: number of proxies to be calculated\n",
    "        :return r0: Array of proxies\n",
    "        \"\"\"\n",
    "        r0 = np.array(y)\n",
    "        yhatt = 1\n",
    "        for i in range(0, n_proxy - 1):\n",
    "            (yhat, yhatt) = self.tprf(X, y, r0, False)\n",
    "            r0 = np.hstack([y - yhat, r0])\n",
    "        return r0\n",
    "    def tprf(self, X, y, Z, oos_present, oos=[]):\n",
    "        \"\"\"\n",
    "        Computes the returns (y) based on the set of predictors\n",
    "        (X) and proxies (Z) using the three pass regression filter method\n",
    "\n",
    "        :param X: Array of predictors (Shape: T x N, where\n",
    "        T = number of timestamps in the training set,\n",
    "        N = number of predictors)\n",
    "        :param y: Array of returns (Shape: T x 1, where\n",
    "        T = number of timestamps in the training set)\n",
    "        :param Z: Array of proxies (Shape: T x L, where\n",
    "        T = number of timestamps in the training set,\n",
    "        L = number of proxies)\n",
    "        :param oos_present: True if out of sample data is present (oos),\n",
    "        False otherwise\n",
    "        :param oos: Out of sample data (predictors)(Shape: 1 x N)\n",
    "        :return yhat: Forecasted returns for in sample data (Shape: T x 1)\n",
    "        :return yhatt: Forecasted return for out of sample array of predictors (float)\n",
    "        \"\"\"\n",
    "\n",
    "        # Pass 1 (Dependent - Value of predictor i across given time intervals,\n",
    "        # Independent - Set of proxies)\n",
    "\n",
    "        phi = np.ndarray(shape=(X.shape[1], Z.shape[1]))\n",
    "        eta = []\n",
    "        for i in range(0, X.shape[1]):\n",
    "            first_pass_model = LR()\n",
    "            first_pass_model = first_pass_model.fit(X=Z, y=X[:, i])\n",
    "            phi[i, :] = first_pass_model.coef_\n",
    "            eta.append(first_pass_model.intercept_)\n",
    "\n",
    "        # Pass 2 (Dependant - Cross section of predictor values at time t,\n",
    "        # Independent - phi (from Pass 1)\n",
    "\n",
    "        eta = np.array(eta).reshape(X.shape[1], 1)\n",
    "        sigma = np.ndarray(shape=(X.shape[0], Z.shape[1]))\n",
    "        eta1 = []\n",
    "        for t in range(0, X.shape[0]):\n",
    "            second_pass_model = LR()\n",
    "            second_pass_model.fit(X=phi, y=X[t, :].T)\n",
    "            sigma[t, :] = second_pass_model.coef_.flatten()\n",
    "            eta1.append(second_pass_model.intercept_)\n",
    "\n",
    "        eta1 = np.array(eta1)\n",
    "\n",
    "        # Pass 3 (Dependant - Array of returns, Independent - sigma (from Pass 2)\n",
    "\n",
    "        third_pass_model = LR()\n",
    "        third_pass_model.fit(X=sigma, y=y)\n",
    "        coeff, intercept = (third_pass_model.coef_, third_pass_model.intercept_)\n",
    "        yhat = np.dot(sigma, coeff.T) + intercept\n",
    "\n",
    "        # If out of sample set of predictors is present, compute the forecasted\n",
    "        # return by running the second pass with out of sample predictors as the\n",
    "        # dependant variable, and multiplying the resultant sigma with beta (coeff) from\n",
    "        # the previous third pass and adding the intercept\n",
    "\n",
    "        yhatt = np.nan\n",
    "        if oos_present:\n",
    "            second_pass_model = LR()\n",
    "            second_pass_model.fit(X=phi, y=oos)\n",
    "            sigma = second_pass_model.coef_.flatten()\n",
    "            yhatt = np.dot(sigma, coeff.T) + intercept\n",
    "        return yhat, yhatt\n",
    "    def predict(self, X_train, y_train, X_test_, n_proxies=3, **kwargs):\n",
    "        Z = self.autoproxy(X_train.to_numpy(), y_train.to_numpy().reshape(-1, 1), n_proxies)\n",
    "        X_train = X_train.to_numpy()\n",
    "        X_test_ = X_test_.to_numpy().flatten()\n",
    "        X_train = (X_train.T/np.std(X_train, axis = 0).reshape(-1, 1)).T\n",
    "        X_test_ = (X_test_.T/np.std(X_test_, axis = 0).reshape(-1, 1).flatten()).T\n",
    "        yhat, yhatt = self.tprf(X_train, y_train, Z, True, X_test_)\n",
    "        return yhatt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nowcasting3PRF(NowcastingPH):\n",
    "    def set_classname(self, **kwargs):\n",
    "        self.prefix = f'TPRF{self.kwargs.get(\"lag_order\")}'    # Override class name\n",
    "    def lag_data(self, df, lag_order):\n",
    "        target_lag, tweet_lag, econ_lag = lag_order\n",
    "        lagged_df = ([df] + [df[['target']].shift(l).add_suffix(f'.Q{l}') for l in range(1, target_lag + 1)] + \n",
    "                        [df[[col for col in df.columns if 'TWT' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, tweet_lag + 1)] +\n",
    "                        [df[[col for col in df.columns if 'ECN' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, econ_lag + 1)])\n",
    "        df = pd.concat(lagged_df, axis=1)\n",
    "        df = df.loc[:, ~df.T.duplicated(keep='first')]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fit_model(self, vintage, window, lag_order, **kwargs):\n",
    "        df, target_scaler, econ_scaler = self.load_data(vintage, window=window, **kwargs)\n",
    "        df = self.lag_data(df, lag_order)\n",
    "\n",
    "        X_test = df.loc[vintage + relativedelta(month=3) :, df.columns.drop('target')]\n",
    "        df_train = df.loc[: vintage - relativedelta(months=3), :].dropna()\n",
    "        X_train = df_train.loc[:, df_train.columns.drop('target')]\n",
    "        y_train = df_train.loc[:, 'target']\n",
    "        \n",
    "        model = TPRF()\n",
    "        # model.fit(X_train, y_train)\n",
    "        self.prefix = f'TPRF{lag_order}'    # Override class name\n",
    "\n",
    "        nowcasts = [(model.predict(X_train, y_train, X_test_.to_frame().T) if not X_test_.isnull().values.any() else np.nan) for _, X_test_ in X_test.iterrows()]\n",
    "        nowcasts = list(target_scaler.inverse_transform(np.array(nowcasts).reshape(-1,1)).flatten())\n",
    "        model_desc = f'TPRF{lag_order}'\n",
    "\n",
    "        return nowcasts, model_desc\n",
    "    def load_tweets(self, vintage, window, kmpair, freq='M', **kwargs):\n",
    "        vintage = pd.to_datetime(vintage)\n",
    "        tweets = pd.read_csv('data/PH_Tweets_v4.csv')\n",
    "        tweets['date'] = pd.to_datetime(tweets['date']) + pd.offsets.MonthEnd(0)\n",
    "        tweets = tweets.set_index('date')\n",
    "\n",
    "        if len(kmpair) == 0:\n",
    "            kmpair = {keyword: list(tweets.columns.drop('keyword')) for keyword in tweets['keyword'].unique()}\n",
    "        data = [tweets[tweets['keyword'] == keyword][kmpair[keyword]].add_suffix(f'_{keyword}') for keyword in kmpair.keys()]\n",
    "        tweets = reduce(lambda left, right: pd.merge(left, right, on='date', how='outer', sort=True), data)\n",
    "        \n",
    "        # tweets = tweets.loc[dt.datetime(2010,1,1) : pd.to_datetime(vintage), :]\n",
    "        tweets = tweets.loc[pd.to_datetime(vintage)  - relativedelta(months =  (pd.to_datetime(vintage).month - 1)%3 + window) : pd.to_datetime(vintage), :]\n",
    "        tweets.index = pd.PeriodIndex(tweets.index, freq=freq)\n",
    "        \n",
    "        cols = ['C_00_PE', 'L_00_PE', 'R_00_PE', 'C_00_PU+', 'L_00_PU+', 'R_00_PU+']\n",
    "        for col in cols:\n",
    "            if list(tweets.columns).count(col) > 1:\n",
    "                tweets[col] = tweets[col].clip(lower=1)\n",
    "                tweets[col] = tweets[col].pct_change()\n",
    "            # tweets[col] = scaler.fit_transform(tweets[col].values.reshape(-1, 1))\n",
    "        tweets.loc[:,:] = StandardScaler().fit_transform(tweets)\n",
    "        \n",
    "        ## PCA\n",
    "        # tweets_std = StandardScaler().fit_transform(tweets.values)\n",
    "        # tweets_pca = PCA(n_components=self.kwargs.get(\"n_components\")).fit_transform(tweets_std)\n",
    "        # tweets = pd.DataFrame(tweets_pca, index=tweets.index)\n",
    "        \n",
    "        return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'GDP'\n",
    "kmpair = {}\n",
    "window=13\n",
    "model = Nowcasting3PRF(lag_order=(0,0,0), kmpair=kmpair, target=target) # lag_order = target_lag, tweet_lag, econ_lag\n",
    "summary = model.run(window=window, save_aggregate=True, with_econ=False, with_tweets=True, multiprocess=processes)\n",
    "# summary = pd.read_csv('Results/ENet(2, 1, 0)_W25_TE_summary.csv', parse_dates=['date'])\n",
    "tweets = model.load_tweets('2023-01-01', kmpair=kmpair, window=window+72).loc[dt.datetime(2017,1,1):,:]\n",
    "tweets.index = tweets.index.to_timestamp()\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "axs[0].plot(summary['date'], summary['Nowcast_A'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[0].plot(summary['date'], summary['Actual_A'], label='Actual')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Annual GDP Growth')\n",
    "axs[1].plot(summary['date'], summary['Nowcast_Q'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[1].plot(summary['date'], summary['Actual_Q'], label='Actual')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Quarter GDP Growth')\n",
    "for metric in tweets.columns:\n",
    "    axs[2].plot(tweets.index, tweets[metric], label=metric, alpha=0.5)\n",
    "axs[2].legend(loc=1)\n",
    "axs[2].set_title('Tweet Metrics - SD')\n",
    "fig.show()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adaptive-Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NowcastingALAS(NowcastingPH):\n",
    "    def set_classname(self, **kwargs):\n",
    "        self.prefix = f'ALAS{self.kwargs.get(\"lag_order\")}'    # Override class name\n",
    "    def lag_data(self, df, lag_order):\n",
    "        target_lag, tweet_lag, econ_lag = lag_order\n",
    "        lagged_df = ([df] + [df[['target']].shift(l).add_suffix(f'.Q{l}') for l in range(1, target_lag + 1)] + \n",
    "                        [df[[col for col in df.columns if 'TWT' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, tweet_lag + 1)] +\n",
    "                        [df[[col for col in df.columns if 'ECN' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, econ_lag + 1)])\n",
    "        df = pd.concat(lagged_df, axis=1)\n",
    "        df = df.loc[:, ~df.T.duplicated(keep='first')]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fit_model(self, vintage, window, lag_order, **kwargs):\n",
    "        df, target_scaler, econ_scaler = self.load_data(vintage, window=window, **kwargs)\n",
    "        df = self.lag_data(df, lag_order)\n",
    "        \n",
    "        X_test = df.loc[vintage + relativedelta(month=3) :, df.columns.drop('target')]\n",
    "        df_train = df.loc[: vintage - relativedelta(months=3), :].dropna()\n",
    "        X_train = df_train.loc[:, df_train.columns.drop('target')]\n",
    "        y_train = df_train.loc[:, 'target']\n",
    "        \n",
    "        weights = asgl.WEIGHTS(penalization='alasso', weight_technique='pls_pct', lasso_power_weight=[1.2],\n",
    "                     gl_power_weight=[1.2], variability_pct=0.5)\n",
    "        lasso_weights, gl_weights = weights.fit(x=X_train.to_numpy(), y=y_train.to_numpy())\n",
    "        model = asgl.ASGL(model='lm', penalization='alasso', lambda1 = [0.1], lasso_weights = lasso_weights)\n",
    "        model.fit(x=X_train.to_numpy(),y=y_train.to_numpy())\n",
    "        self.prefix = f'ALAS{lag_order}'    # Override class name\n",
    "\n",
    "        nowcasts = [(model.predict(x_new=X_test_.to_frame().T.to_numpy()) if not X_test_.isnull().values.any() else np.nan) for _, X_test_ in X_test.iterrows()]\n",
    "        # nowcasts = list(target_scaler.inverse_transform(np.array(nowcasts).reshape(-1,1)).flatten())\n",
    "        nowcasts = [(target_scaler.inverse_transform(nowcast).flatten().item() if not np.isnan(nowcast) else np.nan) for nowcast in nowcasts]\n",
    "        model_desc = f'ALAS{lag_order}'\n",
    "\n",
    "        return nowcasts, model_desc\n",
    "    def load_tweets(self, vintage, window, kmpair, freq='M', **kwargs):\n",
    "        vintage = pd.to_datetime(vintage)\n",
    "        tweets = pd.read_csv('data/PH_Tweets_v3.csv')\n",
    "        tweets['date'] = pd.to_datetime(tweets['date']) + pd.offsets.MonthEnd(0)\n",
    "        tweets = tweets.set_index('date')\n",
    "\n",
    "        if len(kmpair) == 0:\n",
    "            kmpair = {keyword: list(tweets.columns.drop('keyword')) for keyword in tweets['keyword'].unique()}\n",
    "        data = [tweets[tweets['keyword'] == keyword][kmpair[keyword]].add_suffix(f'_{keyword}') for keyword in kmpair.keys()]\n",
    "        tweets = reduce(lambda left, right: pd.merge(left, right, on='date', how='outer', sort=True), data)\n",
    "\n",
    "        # tweets = tweets.loc[dt.datetime(2010,1,1) : pd.to_datetime(vintage), :]\n",
    "        tweets = tweets.loc[pd.to_datetime(vintage)  - relativedelta(months =  (pd.to_datetime(vintage).month - 1)%3 + window) : pd.to_datetime(vintage), :]\n",
    "        tweets.index = pd.PeriodIndex(tweets.index, freq=freq)\n",
    "\n",
    "        tweets.loc[:,:] = StandardScaler().fit_transform(tweets)\n",
    "\n",
    "        return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'GDP'\n",
    "kmpair = {}\n",
    "window=13\n",
    "model = NowcastingALAS(lag_order=(0,0,0), kmpair=kmpair, target=target) # lag_order = target_lag, tweet_lag, econ_lag\n",
    "summary = model.run(window=window, save_aggregate=True, with_econ=False, with_tweets=True, multiprocess=processes)\n",
    "# summary = pd.read_csv('Results/ENet(2, 1, 0)_W25_TE_summary.csv', parse_dates=['date'])\n",
    "tweets = model.load_tweets('2023-01-01', kmpair=kmpair, window=window+72).loc[dt.datetime(2017,1,1):,:]\n",
    "tweets.index = tweets.index.to_timestamp()\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "axs[0].plot(summary['date'], summary['Nowcast_A'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[0].plot(summary['date'], summary['Actual_A'], label='Actual')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Annual GDP Growth')\n",
    "axs[1].plot(summary['date'], summary['Nowcast_Q'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[1].plot(summary['date'], summary['Actual_Q'], label='Actual')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Quarter GDP Growth')\n",
    "for metric in tweets.columns:\n",
    "    axs[2].plot(tweets.index, tweets[metric], label=metric, alpha=0.5)\n",
    "axs[2].legend(loc=1)\n",
    "axs[2].set_title('Tweet Metrics - SD')\n",
    "fig.show()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all ML models in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ML models\n",
    "import itertools\n",
    "# windows = [37, 43, 49, 55, 61, 67]\n",
    "windows = [37]\n",
    "models = [NowcastingML, NowcastingMLP, NowcastingSVR, NowcastingExtraTree]\n",
    "run_params = list(itertools.product(windows, models))\n",
    "for param in run_params:\n",
    "    model = param[1](lag_order=(4,1,0), target='GDP', kmpair={})\n",
    "    summary = model.run(window=param[0], save_aggregate=True, with_econ=False, with_tweets=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NowcastingAR(NowcastingPH):\n",
    "    def fit_model(self, vintage, window, AR_order, **kwargs):\n",
    "        df, target_scaler, econ_scaler = self.load_data(vintage, window=window, **kwargs)\n",
    "\n",
    "        model = AutoReg(df['target'].dropna(), lags=AR_order).fit()\n",
    "        self.prefix = 'AR(1)'    # Override class name\n",
    "        \n",
    "        nowcasts = model.predict(start=f'{vintage.year}Q1', end=f'{vintage.year}Q4').to_numpy().reshape(-1,1)\n",
    "        nowcasts = list(target_scaler.inverse_transform(nowcasts).flatten())\n",
    "        model_desc = 'AR(1)'\n",
    "\n",
    "        return nowcasts, model_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NowcastingAR(AR_order=1, kmpair={}, target='GDP')\n",
    "summary = model.run(window=25, save_aggregate=True)\n",
    "# summary = pd.read_csv('Results/AR(1)_W25_TE_summary.csv', parse_dates=['date'])\n",
    "tweets = model.load_tweets('2023-01-01').loc[dt.datetime(2017,1,1):,:]\n",
    "tweets.index = tweets.index.to_timestamp()\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "axs[0].plot(summary['date'], summary['Nowcast_A'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[0].plot(summary['date'], summary['Actual_A'], label='Actual')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Annual GDP Growth')\n",
    "axs[1].plot(summary['date'], summary['Nowcast_Q'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[1].plot(summary['date'], summary['Actual_Q'], label='Actual')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Quarter GDP Growth')\n",
    "for metric in tweets.columns:\n",
    "    axs[2].plot(tweets.index, tweets[metric], label=metric, alpha=0.5)\n",
    "axs[2].legend()\n",
    "axs[2].set_title('Tweet Metrics')\n",
    "fig.show()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run AR models in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AR models\n",
    "import itertools\n",
    "windows = [25, 31, 37, 43, 49, 55]\n",
    "for window in windows:\n",
    "    model = NowcastingAR(AR_order=1, target='GDP', kmpair={})\n",
    "    summary = model.run(window=window, save_aggregate=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning x Dynamic Factor Model (do not use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NowcastingMLxDFM(NowcastingPH):\n",
    "    def extend_data(self, df, vintage, DFM_order, optimize_order=False, **kwargs):\n",
    "        factor_order, error_order, k_factors, factor_lag = DFM_order\n",
    "\n",
    "        if optimize_order:\n",
    "            model = OptimizeExtendedDynamicFactor(\n",
    "                endog=df, k_factors_max=k_factors, factor_lag_max=factor_lag, factor_order_max=factor_order, \n",
    "                error_order=error_order, **kwargs).optimize(**kwargs)\n",
    "        else:\n",
    "            model = ExtendedDynamicFactor(\n",
    "                endog=df, k_factors=k_factors, factor_lag=factor_lag, factor_order=factor_order, \n",
    "                error_order=error_order, **kwargs)\n",
    "        results = model.fit(disp=False, maxiter=1000, method='powell', ftol=1e-5, **kwargs)\n",
    "        \n",
    "        df_extended = pd.DataFrame()\n",
    "        for col in df.columns:\n",
    "            col_extended = pd.concat([df[[col]].dropna(), \n",
    "                                    results.predict(start=df[col].dropna().index[-1], end=vintage + pd.offsets.YearEnd(0))[[col]].iloc[1:]])\n",
    "            df_extended = pd.concat([df_extended, col_extended], axis=1)\n",
    "        df_extended.index.name = df.index.name\n",
    "\n",
    "        return df_extended\n",
    "\n",
    "    def load_econ_m(self, vintage, freq='M', extend=False, **kwargs):\n",
    "        econ_m = super().load_econ_m(vintage, freq='M', **kwargs)\n",
    "        econ_m = self.extend_data(econ_m, vintage, **kwargs) if extend else econ_m\n",
    "        econ_m.index = pd.PeriodIndex(econ_m.index, freq=freq)\n",
    "        return econ_m\n",
    "    \n",
    "    def load_econ_q(self, vintage, freq='Q', extend=False, **kwargs):\n",
    "        econ_q = super().load_econ_q(vintage, freq='Q', **kwargs)\n",
    "        econ_q = self.extend_data(econ_q, vintage, **kwargs) if extend else econ_q\n",
    "        econ_q.index = pd.PeriodIndex(econ_q.index, freq=freq)\n",
    "        return econ_q\n",
    "    \n",
    "    def load_tweets(self, vintage, freq='M', extend=False, **kwargs):\n",
    "        tweets = super().load_tweets(vintage, freq='M', **kwargs)\n",
    "        tweets = self.extend_data(tweets, vintage, **kwargs) if extend else tweets\n",
    "        tweets.index = pd.PeriodIndex(tweets.index, freq=freq)\n",
    "        return tweets\n",
    "    \n",
    "    def lag_data(self, df, lag_order):\n",
    "        target_lag, tweet_lag, econ_lag = lag_order\n",
    "        lagged_df = ([df] + [df[['target']].shift(l).add_suffix(f'.Q{l}') for l in range(1, target_lag + 1)] + \n",
    "                        [df[[col for col in df.columns if 'TWT' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, tweet_lag + 1)] +\n",
    "                        [df[[col for col in df.columns if 'ECN' in col]].shift(l).add_suffix(f'.Q{l}') for l in range(1, econ_lag + 1)])\n",
    "        df = pd.concat(lagged_df, axis=1)\n",
    "        df = df.loc[:, ~df.T.duplicated(keep='first')]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fit_model(self, vintage, window, lag_order, DFM_order, optimize_order=False, **kwargs):\n",
    "        df_train, _, _ = self.load_data(vintage, window=window, scaled=False, **kwargs)\n",
    "        df_train = self.lag_data(df_train, lag_order).dropna()\n",
    "        X_train = df_train.loc[:, df_train.columns.drop('target')]\n",
    "        y_train = df_train.loc[:, 'target']\n",
    "\n",
    "        df, _, _ = self.load_data(vintage, window=window, scaled=False, extend=True, DFM_order=DFM_order, optimize_order=optimize_order, **kwargs)\n",
    "        df = self.lag_data(df, lag_order)\n",
    "        X_test = df.loc[vintage + relativedelta(month=3) :, df.columns.drop('target')]\n",
    "        \n",
    "        model = ElasticNet()\n",
    "        model.fit(X_train, y_train)\n",
    "        self.prefix = f'ENet{lag_order} x ' + ('DFM_Opt' if optimize_order else f'DFM{DFM_order}')   # Override class name\n",
    "\n",
    "        nowcasts = [(model.predict(X_test_.to_frame().T)[0] if not X_test_.isnull().values.any() else np.nan) for _, X_test_ in X_test.iterrows()]\n",
    "        model_desc = f'ENet{lag_order} x ' + ('DFM_Opt' if optimize_order else f'DFM{DFM_order}')\n",
    "\n",
    "        return nowcasts, model_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag_order = target_lag, tweet_lag, econ_lag \n",
    "# DFM_order = factor_order, error_order, k_factors, factor_lag\n",
    "model = NowcastingMLxDFM(lag_order=(1,0,0), DFM_order=(1,0,1,0), optimize_order=False)\n",
    "summary = model.run(window=25, save_aggregate=False)\n",
    "# summary = pd.read_csv('Results/ENet(1, 0, 0) x DFM(1, 0, 1, 0)_W25_TE_summary.csv', parse_dates=['date'])\n",
    "tweets = model.load_tweets('2023-01-01').loc[dt.datetime(2017,1,1):,:]\n",
    "tweets.index = tweets.index.to_timestamp()\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "axs[0].plot(summary['date'], summary['Nowcast_A'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[0].plot(summary['date'], summary['Actual_A'], label='Actual')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Annual GDP Growth')\n",
    "axs[1].plot(summary['date'], summary['Nowcast_Q'], linewidth=0, marker='*', label='Nowcast')\n",
    "axs[1].plot(summary['date'], summary['Actual_Q'], label='Actual')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Quarter GDP Growth')\n",
    "for metric in tweets.columns:\n",
    "    axs[2].plot(tweets.index, tweets[metric], label=metric, alpha=0.5)\n",
    "axs[2].legend()\n",
    "axs[2].set_title('Tweet Metrics')\n",
    "fig.show()\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "912f7fec6d142835d8bc345c49717af8ab053dbe34634e5a7992729e29ff09d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
